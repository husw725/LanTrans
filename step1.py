import streamlit as st
from openai import OpenAI
from key import key as API_KEY
import os
import json
import time
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed

# æ¨¡å‹è´¹ç”¨è¡¨
MODEL_COST = {
    "gpt-5": {"input": 1.25, "output": 10.0},       # $/1M tokens
    "gpt-5-mini": {"input": 0.25, "output": 2.0},
    "gpt-5-nano": {"input": 0.05, "output": 0.4},
    # "gpt-5-pro": {"input": 15.0, "output": 120.0}
}

def estimate_cost(input_tokens, output_tokens, model):
    cost = (input_tokens / 1_000_000 * MODEL_COST[model]["input"]) + \
           (output_tokens / 1_000_000 * MODEL_COST[model]["output"])
    return cost

def run():
    client = OpenAI(api_key=API_KEY)
    TEMP_DIR = Path("./temp")
    TEMP_DIR.mkdir(exist_ok=True)

    st.header("Step 1: æ‰¹é‡å¤šè¯­è¨€ç¿»è¯‘ SRTï¼ˆæ”¯æŒæˆæœ¬ä¼°ç®—ï¼‰")

    # è¾“å…¥è¾“å‡ºç›®å½•
    input_dir = st.text_input("è¾“å…¥ SRT æ–‡ä»¶å¤¹è·¯å¾„ï¼š")
    output_root = st.text_input("è¾“å‡ºç¿»è¯‘ç»“æœæ–‡ä»¶å¤¹è·¯å¾„ï¼š")

    LANG_OPTIONS = {
        "é˜¿æ‹‰ä¼¯è¯­ (Arabic)": "Arabic",
        "è‹±è¯­ (English)": "English",
        "è¥¿ç­ç‰™è¯­ (Spanish)": "Spanish",
        "è‘¡è„ç‰™è¯­ (Portuguese)": "Portuguese",
        "å¾·è¯­ (German)": "German",
        "æ³•è¯­ (French)": "French",
        "æ„å¤§åˆ©è¯­ (Italian)": "Italian",
        "å°å°¼è¯­ (Indonesian)": "Indonesian",
        "å°åœ°è¯­ (Hindi)": "Hindi",
        "æ³°è¯­ (Thai)": "Thai",
        "é©¬æ¥è¯­ (Malay)": "Malay",
        "æ—¥æœ¬è¯­ (Japanese)": "Japanese",
        "éŸ©è¯­ (Korean)": "Korean",
        "ä¸­æ–‡ï¼ˆç¹ä½“ï¼‰ (Traditional Chinese)": "Traditional Chinese"
    }

    target_displays = st.multiselect("é€‰æ‹©ç›®æ ‡è¯­è¨€ï¼ˆå¯å¤šé€‰ï¼‰", list(LANG_OPTIONS.keys()))
    target_langs = [LANG_OPTIONS[d] for d in target_displays]

    # æ¨¡å‹é€‰æ‹©
    translate_model = st.selectbox("ç¿»è¯‘æ¨¡å‹", [ "gpt-5","gpt-5-mini", "gpt-5-nano"], index=0)
    memory_model = st.selectbox("Memory æ›´æ–°æ¨¡å‹", [ "gpt-5","gpt-5-mini", "gpt-5-nano",], index=0)

    reset = st.checkbox("é‡æ–°å¼€å§‹æ‰€æœ‰è¯­è¨€çš„ç¿»è¯‘ï¼Ÿ", key="reset_all")

    if st.button("å¼€å§‹æ‰¹é‡ç¿»è¯‘"):
        if not input_dir or not os.path.exists(input_dir):
            st.warning("è¯·æä¾›æœ‰æ•ˆçš„è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„ï¼")
            return
        if not output_root:
            st.warning("è¯·æä¾›è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„ï¼")
            return
        if not target_langs:
            st.warning("è¯·é€‰æ‹©è‡³å°‘ä¸€ç§è¯­è¨€ï¼")
            return

        srt_files = sorted([f for f in os.listdir(input_dir) if f.lower().endswith(".srt")])
        if not srt_files:
            st.warning("è¾“å…¥æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ‰¾åˆ° SRT æ–‡ä»¶ï¼")
            return

        # æ¯è¯­è¨€ç¿»è¯‘ä»»åŠ¡
        def process_language(lang):
            memory_path = TEMP_DIR / f"drama_memory_{lang}.json"
            output_dir = Path(output_root) / lang
            output_dir.mkdir(parents=True, exist_ok=True)

            # åˆå§‹åŒ–æˆ–é‡ç½®è®°å¿†
            if reset and memory_path.exists():
                memory_path.unlink()
            if memory_path.exists():
                try:
                    memory = json.load(open(memory_path, "r", encoding="utf-8"))
                except:
                    memory = {"episode_count": 0, "characters": {}, "terminology": {}, "style_notes": ""}
            else:
                memory = {"episode_count": 0, "characters": {}, "terminology": {}, "style_notes": ""}

            results = []
            total_cost = 0.0

            for idx, srt_file in enumerate(srt_files, start=1):
                input_path = os.path.join(input_dir, srt_file)
                output_path = output_dir / srt_file
                if output_path.exists():
                    results.append(f"è·³è¿‡ {lang} - {srt_file}")
                    continue

                with open(input_path, "r", encoding="utf-8") as f:
                    srt_content = f.read()

                # ç¿»è¯‘è¯·æ±‚
                system_prompt = f"""
                You are a professional subtitle translator for short dramas.
                Translate subtitles into {lang} while preserving SRT format, tone, and style.
                Current memory: {memory}
                Do not add any translator notes outside of SRT.
                """
                user_prompt = f"Translate the following subtitles:\n{srt_content}"

                for _ in range(3):
                    try:
                        resp = client.chat.completions.create(
                            model=translate_model,
                            messages=[
                                {"role": "system", "content": system_prompt},
                                {"role": "user", "content": user_prompt}
                            ]
                        )
                        translated_srt = resp.choices[0].message.content.strip()
                        input_tokens = len(system_prompt.split()) + len(user_prompt.split())
                        output_tokens = len(translated_srt.split())
                        cost = estimate_cost(input_tokens, output_tokens, translate_model)
                        total_cost += cost
                        break
                    except Exception:
                        time.sleep(2)
                else:
                    results.append(f"{lang} - {srt_file} ç¿»è¯‘å¤±è´¥")
                    continue

                # æ›´æ–° memory
                update_prompt = f"""
                Analyze the following translated SRT and update the memory for characters, terminology, and style notes.
                Previous memory: {memory}
                Translated SRT:\n{translated_srt}
                Output the updated memory in JSON format.
                """
                try:
                    upd_resp = client.chat.completions.create(
                        model=memory_model,
                        messages=[
                            {"role": "system", "content": "You are a memory updater for a subtitle translation system."},
                            {"role": "user", "content": update_prompt}
                        ]
                    )
                    new_memory = json.loads(upd_resp.choices[0].message.content.strip())
                    memory.update(new_memory)
                    json.dump(memory, open(memory_path, "w", encoding="utf-8"), ensure_ascii=False, indent=2)
                    mem_tokens = len(update_prompt.split()) + len(json.dumps(new_memory).split())
                    total_cost += estimate_cost(mem_tokens, 0, memory_model)
                except Exception:
                    results.append(f"âš ï¸ {lang} - {srt_file} memory æ›´æ–°å¤±è´¥")

                with open(output_path, "w", encoding="utf-8") as f:
                    f.write(translated_srt)
                results.append(f"âœ… å®Œæˆ {lang} - {srt_file}, è´¹ç”¨ ${total_cost:.4f}")

            results.append(f"ğŸ’° {lang} æ€»è´¹ç”¨: ${total_cost:.4f}")
            return results

        # å¤šè¯­è¨€å¹¶å‘
        progress = st.progress(0)
        total = len(target_langs)
        done = 0

        with ThreadPoolExecutor(max_workers=min(len(target_langs), 4)) as executor:
            futures = {executor.submit(process_language, lang): lang for lang in target_langs}
            for future in as_completed(futures):
                lang = futures[future]
                try:
                    result_list = future.result()
                    for msg in result_list:
                        st.write(msg)
                except Exception as e:
                    st.error(f"{lang} å¤„ç†å‡ºé”™: {e}")
                done += 1
                progress.progress(done / total)

        st.success("âœ… æ‰€æœ‰è¯­è¨€ç¿»è¯‘å®Œæˆï¼")