import streamlit as st
from pathlib import Path
from moviepy.editor import VideoFileClip, TextClip, CompositeVideoClip
from PIL import Image, ImageFont
import pysrt
import os
from dotenv import load_dotenv
load_dotenv()

# --- Configuration & Helpers ---

is_windows = os.name == "nt"
if is_windows:
    import moviepy.config as mpy_config
    imagemagick_binary = os.getenv("IMAGEMAGICK_BINARY")
    if imagemagick_binary and os.path.exists(imagemagick_binary):
        mpy_config.change_settings({"IMAGEMAGICK_BINARY": imagemagick_binary})
    default_font_path = r"C:\Windows\Fonts\arial.ttf"
else:
    default_font_path = "Arial"

def srt_time_to_seconds(t):
    return t.hours * 3600 + t.minutes * 60 + t.seconds + t.milliseconds / 1000

def safe_text(text):
    if not text: return ""
    cleaned = "".join(ch for ch in text if ord(ch) >= 32 or ch in "\n\t")
    return cleaned.strip()

def wrap_text_pil(text, font_path, font_size, max_width):
    """Wraps text using PIL for accurate width calculation."""
    font = ImageFont.truetype(font_path, font_size)
    lines = []
    
    for paragraph in text.split('\n'):
        words = paragraph.split(' ')
        current_line = ""
        for word in words:
            if not word: continue
            
            test_line = f"{current_line} {word}".strip()
            
            try:
                line_width = font.getlength(test_line)
            except AttributeError:
                bbox = font.getbbox(test_line)
                line_width = bbox[2] - bbox[0]

            if line_width <= max_width:
                current_line = test_line
            else:
                if not current_line:
                    lines.append(word)
                else:
                    lines.append(current_line)
                    current_line = word
        
        if current_line:
            lines.append(current_line)
            
    return "\n".join(lines)

def generate_subtitle_clips(subs, w, h, style):
    clips = []
    shadow_offset = style.get("shadow_offset", (2, 2))
    shadow_font_size = style.get("shadow_font_size", style["font_size"])

    for sub in subs:
        safe_txt = safe_text(sub.text)
        if not safe_txt: continue

        wrapped_text = wrap_text_pil(safe_txt, style["font_path"], style["font_size"], style["max_text_width"])

        # Shadow Layer
        shadow_clip = TextClip(
            wrapped_text, fontsize=shadow_font_size, color=style["shadow_color"],
            method="label", align="center", font=style["font_path"]
        ).set_opacity(style["shadow_opacity"]).set_position((
            'center', h - style["bottom_offset"] + shadow_offset[1]
        ))
        
        # Text Layer
        txt_clip = TextClip(
            wrapped_text, fontsize=style["font_size"], color=style["font_color"],
            stroke_color=style["stroke_color"], stroke_width=style["stroke_width"],
            method="label", align="center", font=style["font_path"]
        ).set_position(('center', h - style["bottom_offset"]))
        
        start, end = srt_time_to_seconds(sub.start), srt_time_to_seconds(sub.end)
        shadow_clip = shadow_clip.set_start(start).set_end(end)
        txt_clip = txt_clip.set_start(start).set_end(end)
        clips.extend([shadow_clip, txt_clip])
    return clips

# --- Main Application ---
def run():
    st.header("ðŸŽ¨ Step 3: æ·»åŠ è§†é¢‘å­—å¹•")
    st.caption("å¯è§†åŒ–è®¾è®¡å­—å¹•æ ·å¼ï¼Œå¹¶å°†å…¶æ‰¹é‡åº”ç”¨åˆ°è§†é¢‘ä¸­ã€‚")

    tab1, tab2 = st.tabs(["ðŸŽ¨ å­—å¹•æ ·å¼è®¾è®¡", "ðŸ“¦ æ‰¹é‡æ·»åŠ å­—å¹•"])

    # --- Tab 1: Style Designer ---
    with tab1:
        col1, col2 = st.columns([0.6, 0.4])
        
        with col1:
            st.subheader("ðŸ–¼ï¸ å®žæ—¶é¢„è§ˆ")
            preview_video = st.file_uploader("é€‰æ‹©ä¸€ä¸ªè§†é¢‘ç”¨äºŽå­—å¹•æ ·å¼é¢„è§ˆ", type=["mp4", "mov", "mkv"])
            
            if preview_video:
                temp_video_path = Path("temp_preview_video.mp4")
                with open(temp_video_path, "wb") as f:
                    f.write(preview_video.read())
                
                try:
                    with VideoFileClip(str(temp_video_path)) as clip:
                        frame = clip.get_frame(1.0) # Get a frame for preview background
                        st.session_state['preview_frame'] = Image.fromarray(frame)
                        st.session_state['video_size'] = clip.size
                except Exception as e:
                    st.error(f"è§†é¢‘åŠ è½½å¤±è´¥: {e}")
                    del st.session_state['preview_frame']

        with col2:
            st.subheader("âš™ï¸ æ ·å¼å‚æ•°")
            
            uploaded_font = st.file_uploader("ä¸Šä¼ è‡ªå®šä¹‰å­—ä½“ (.ttf)", type=["ttf"])
            font_path = default_font_path
            if uploaded_font:
                font_path = Path("uploaded_font.ttf")
                with open(font_path, "wb") as f: f.write(uploaded_font.read())

            if 'video_size' in st.session_state:
                w, h = st.session_state['video_size']
                
                with st.container(border=True):
                    st.markdown("**å­—ä½“ä¸Žé¢œè‰²**")
                    font_size = st.slider("å­—ä½“å¤§å°", 12, 100, 48)
                    font_color = st.color_picker("å­—ä½“é¢œè‰²", "#FFFFFF")
                with st.container(border=True):
                    st.markdown("**æè¾¹**")
                    stroke_width = st.slider("æè¾¹å®½åº¦", 0, 5, 1)
                    stroke_color = st.color_picker("æè¾¹é¢œè‰²", "#000000")
                with st.container(border=True):
                    st.markdown("**ä½ç½®ä¸Žå°ºå¯¸**")
                    bottom_offset = st.slider("è·åº•éƒ¨è·ç¦»(px)", 0, h // 2, 80)
                    width_ratio = st.slider("æœ€å¤§å®½åº¦æ¯”ä¾‹", 0.2, 1.0, 0.8, step=0.05)
                with st.container(border=True):
                    st.markdown("**é˜´å½±**")
                    shadow_opacity = st.slider("é˜´å½±ä¸é€æ˜Žåº¦", 0.0, 1.0, 0.5)
                    shadow_color = st.color_picker("é˜´å½±é¢œè‰²", "#000000")
                    shadow_offset_y = st.slider("é˜´å½±åž‚ç›´åç§»(px)", -10, 10, 2)

                style = {
                    "font_path": str(font_path), "font_size": font_size, "font_color": font_color,
                    "stroke_color": stroke_color, "stroke_width": stroke_width, "bottom_offset": bottom_offset,
                    "max_text_width": int(w * width_ratio), "shadow_color": shadow_color,
                    "shadow_opacity": shadow_opacity, "shadow_offset": (0, shadow_offset_y),
                }
                st.session_state["subtitle_style"] = style
                st.success("âœ… æ ·å¼å·²æš‚å­˜")

        if 'preview_frame' in st.session_state and 'subtitle_style' in st.session_state:
            with col1:
                style = st.session_state["subtitle_style"]
                preview_img = st.session_state['preview_frame'].copy()
                w, h = st.session_state['video_size']

                # Create a dummy subtitle clip for preview
                preview_text = "è¿™æ˜¯å­—å¹•é¢„è§ˆï¼Œè¿™æ®µæ–‡å­—ä¼šå±•ç¤ºæ¢è¡Œæ•ˆæžœã€‚"
                wrapped_preview_text = wrap_text_pil(preview_text, style["font_path"], style["font_size"], style["max_text_width"])

                txt_clip_preview = TextClip(
                    wrapped_preview_text, fontsize=style['font_size'], color=style['font_color'],
                    stroke_color=style['stroke_color'], stroke_width=style['stroke_width'],
                    method='label', align='center', font=style['font_path']
                ).set_position(('center', h - style['bottom_offset']))
                
                shadow_font_size = style.get("shadow_font_size", style["font_size"])
                shadow_clip_preview = TextClip(
                    wrapped_preview_text, fontsize=shadow_font_size, color=style['shadow_color'],
                    method='label', align='center', font=style['font_path']
                ).set_opacity(style['shadow_opacity']).set_position(('center', h - style['bottom_offset'] + style['shadow_offset'][1]))

                # Composite onto the frame
                final_clip = CompositeVideoClip([VideoFileClip(str(temp_video_path)).subclip(0,1), shadow_clip_preview, txt_clip_preview])
                final_frame = final_clip.get_frame(0.5)
                st.image(Image.fromarray(final_frame), caption="å­—å¹•æ ·å¼é¢„è§ˆ")

    # --- Tab 2: Batch Processing ---
    with tab2:
        with st.container(border=True):
            st.subheader("ðŸ“ è·¯å¾„è®¾ç½®")
            p_col1, p_col2, p_col3 = st.columns(3)
            with p_col1: video_dir = st.text_input("è§†é¢‘æ–‡ä»¶å¤¹è·¯å¾„")
            with p_col2: srt_dir = st.text_input("SRT æ–‡ä»¶å¤¹è·¯å¾„")
            with p_col3: output_dir = st.text_input("è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„")
        
        with st.container(border=True):
            st.subheader("âš™ï¸ å¤„ç†é€‰é¡¹")
            s_col1, s_col2 = st.columns(2)
            with s_col1: match_mode = st.radio("SRT åŒ¹é…æ–¹å¼", ("æŒ‰æ–‡ä»¶ååŒ¹é…", "æŒ‰é¡ºåºå¯¹åº”"))
            with s_col2:
                crf = st.select_slider("è¾“å‡ºåŽ‹ç¼©è´¨é‡", options=[18, 20, 23, 28], value=23, help="CRFå€¼è¶Šä½Žï¼Œè´¨é‡è¶Šé«˜ä½“ç§¯è¶Šå¤§ã€‚18é«˜è´¨é‡, 23å‡è¡¡, 28å°ä½“ç§¯ã€‚")

        st.divider()
        if st.button("ðŸš€ å¼€å§‹æ‰¹é‡æ·»åŠ å­—å¹•", type="primary", use_container_width=True):
            if "subtitle_style" not in st.session_state:
                st.warning("è¯·å…ˆåœ¨â€œå­—å¹•æ ·å¼è®¾è®¡â€é€‰é¡¹å¡ä¸­è®¾ç½®å¹¶æš‚å­˜æ ·å¼ï¼")
                return
            # (Validation and processing logic remains similar to original)
            style = st.session_state["subtitle_style"]
            Path(output_dir).mkdir(parents=True, exist_ok=True)
            video_files = sorted([f for f in os.listdir(video_dir) if f.lower().endswith((".mp4", ".mov"))])
            srt_files = sorted([f for f in os.listdir(srt_dir) if f.lower().endswith(".srt")])

            progress_bar = st.progress(0, "å‡†å¤‡å¼€å§‹...")
            log_container = st.container(height=300, border=True)

            for i, video_name in enumerate(video_files):
                progress_bar.progress((i + 1) / len(video_files), f"æ­£åœ¨å¤„ç†: {video_name}")
                # ... (rest of the file processing logic is largely the same)
                video_path = Path(video_dir) / video_name
                output_path = Path(output_dir) / video_name
                srt_name = Path(video_name).stem + ".srt" if "æ–‡ä»¶å" in match_mode else srt_files[i]
                srt_path = Path(srt_dir) / srt_name

                if not srt_path.exists():
                    log_container.warning(f"âš ï¸ {video_name} å¯¹åº”çš„ SRT ({srt_name}) æœªæ‰¾åˆ°ï¼Œè·³è¿‡ã€‚")
                    continue
                
                try:
                    video_clip = VideoFileClip(str(video_path))
                    subs = pysrt.open(str(srt_path), encoding='utf-8')
                    subtitle_clips = generate_subtitle_clips(subs, video_clip.w, video_clip.h, style)
                    final_video = CompositeVideoClip([video_clip, *subtitle_clips])
                    final_video.write_videofile(
                        str(output_path), codec="libx264", audio_codec="aac", preset="slow",
                        ffmpeg_params=["-crf", str(crf)], threads=4
                    )
                    log_container.success(f"âœ… {video_name} å·²å¤„ç†å®Œæˆã€‚")
                except Exception as e:
                    log_container.error(f"âŒ å¤„ç† {video_name} æ—¶å‡ºé”™: {e}")

            st.balloons()
            st.success("ðŸŽ‰ æ‰€æœ‰è§†é¢‘å·²å¤„ç†å®Œæˆï¼")